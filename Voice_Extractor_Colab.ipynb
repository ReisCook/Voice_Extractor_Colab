{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ee9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Mount Google Drive & Install Dependencies\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Clone repo and install\n",
    "!git clone -q https://github.com/ReisCook/Voice_Extractor.git\n",
    "!pip install -q -r Voice_Extractor/requirements.txt ipywidgets pandas matplotlib huggingface_hub datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from IPython.display import display, Audio, clear_output, HTML\n",
    "from google.colab import files, output\n",
    "from huggingface_hub import login, HfApi\n",
    "from pathlib import Path\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    /* General Styles */\n",
    "    .widget-label { min-width: 180px !important; font-weight: bold; display: flex; align-items: center;}\n",
    "    .widget-text input[type=\"text\"], .widget-text input[type=\"password\"], .widget-text textarea { width: calc(100% - 16px); box-sizing: border-box; }\n",
    "    .widget-dropdown select { min-width: 200px; }\n",
    "    .widget-button { margin: 5px 0; }\n",
    "    .full-width-widget > .widget-label { width: 100% !important; } /* Forcing label to take full width for some widgets */\n",
    "\n",
    "    /* Section Styling */\n",
    "    .section-header { font-size: 1.3em; font-weight: bold; color: #1A73E8; margin-top: 25px; margin-bottom: 15px; padding-bottom: 5px; border-bottom: 2px solid #1A73E8;}\n",
    "    .subsection-header { font-size: 1.1em; font-weight: bold; color: #34A853; margin-top: 20px; margin-bottom: 10px;}\n",
    "\n",
    "    /* File Picker & Input Rows */\n",
    "    .input-row { display: flex; align-items: center; margin-bottom: 8px; width: 100%; }\n",
    "    .input-row > .widget-label { flex-basis: 200px; flex-shrink: 0; margin-right: 10px; }\n",
    "    .input-row > .widget-text, .input-row > .widget-dropdown { flex-grow: 1; }\n",
    "    .input-row .widget-button { margin-left: 10px; min-width: 90px; }\n",
    "    \n",
    "    /* Tooltips */\n",
    "    .tooltip-container { position: relative; display: inline-block; margin-left: 5px; }\n",
    "    .tooltip-icon { color: #5f6368; cursor: help; }\n",
    "    .tooltip-text {\n",
    "        visibility: hidden; width: 280px; background-color: #333; color: #fff; text-align: left;\n",
    "        border-radius: 6px; padding: 8px; position: absolute; z-index: 100;\n",
    "        bottom: 130%; left: 50%; margin-left: -140px; opacity: 0; transition: opacity 0.3s;\n",
    "        font-size: 0.9em; line-height: 1.4;\n",
    "    }\n",
    "    .tooltip-container:hover .tooltip-text { visibility: visible; opacity: 1; }\n",
    "\n",
    "    /* Log Area & Status */\n",
    "    .log-area-container { border: 1px solid #ccc; height: 400px; overflow-y: scroll; padding: 10px; background-color: #f9f9f9; margin-top: 15px; font-family: monospace; font-size: 0.9em; white-space: pre-wrap; }\n",
    "    .status-message-container { margin-top: 15px; padding: 10px; border-radius: 5px; font-weight: bold; text-align: center; }\n",
    "    .status-ready { background-color: #e0e0e0; color: #333; }\n",
    "    .status-processing { background-color: #fff3cd; color: #856404; border: 1px solid #ffeeba; } /* Bootstrap warning yellow */\n",
    "    .status-success { background-color: #d4edda; color: #155724; border: 1px solid #c3e6cb; } /* Bootstrap success green */\n",
    "    .status-error { background-color: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; } /* Bootstrap danger red */\n",
    "\n",
    "    /* Accordion Styling */\n",
    "    .widget-accordion .accordion-header { background-color: #f0f0f0; padding: 8px; margin-top: 5px; border: 1px solid #ddd; }\n",
    "    .widget-accordion .widget-box { padding: 10px; border: 1px solid #ddd; border-top: none; }\n",
    "    \n",
    "    /* Button Styling */\n",
    "    .start-button { font-size: 1.1em; padding: 10px 15px; }\n",
    "    .widget-radio-buttons label { margin-right: 15px; }\n",
    "    .disabled-widget-note { color: #777; font-style: italic; font-size: 0.9em; margin-left: 5px;}\n",
    "\n",
    "</style>\n",
    "<!-- Font Awesome for tooltips -->\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n",
    "\"\"\"))\n",
    "\n",
    "# Helper Functions\n",
    "def create_tooltip_html(tooltip_text):\n",
    "    \"\"\"Creates an HTML tooltip with Font Awesome icon.\"\"\"\n",
    "    return f'<div class=\"tooltip-container\"><i class=\"fas fa-info-circle tooltip-icon\"></i><span class=\"tooltip-text\">{tooltip_text}</span></div>'\n",
    "\n",
    "def create_file_input_row(description_text, placeholder_text, tooltip_content, initial_value=\"\", is_folder=False):\n",
    "    \"\"\"Creates an input row with label, text input, browse button, and tooltip.\"\"\"\n",
    "    label = widgets.Label(description_text)\n",
    "    text_widget = widgets.Text(value=initial_value, placeholder=placeholder_text)\n",
    "    button = widgets.Button(description=\"Browse\", icon=\"folder-open\" if is_folder else \"file-audio\")\n",
    "    tooltip = widgets.HTML(create_tooltip_html(tooltip_content))\n",
    "    \n",
    "    output_widget = widgets.Output()\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        with output_widget:\n",
    "            clear_output()\n",
    "            if is_folder:\n",
    "                text_widget.value = \"/content/drive/MyDrive/\"\n",
    "                print(\"Please manually complete the Google Drive folder path. Example: `/content/drive/MyDrive/my_audio_folder`.\")\n",
    "            else:\n",
    "                try:\n",
    "                    selected = files.pick_file(accept='.wav,.mp3,.m4a,.flac')\n",
    "                    if selected:\n",
    "                        text_widget.value = list(selected.keys())[0]\n",
    "                except TypeError:\n",
    "                    print(\"No file selected.\")\n",
    "    \n",
    "    button.on_click(on_button_click)\n",
    "    \n",
    "    hbox = widgets.HBox([label, text_widget, button, tooltip])\n",
    "    hbox.add_class(\"input-row\")\n",
    "    \n",
    "    # Return combined widget for use in layout\n",
    "    return widgets.VBox([hbox, output_widget]), text_widget\n",
    "\n",
    "def validate_inputs(*args):\n",
    "    \"\"\"Validates required inputs and enables/disables start button accordingly.\"\"\"\n",
    "    required_widgets = [\n",
    "        hf_token_widget, \n",
    "        audio_dir_text, \n",
    "        reference_file_text, \n",
    "        target_name_text, \n",
    "        output_base_dir_text\n",
    "    ]\n",
    "    \n",
    "    all_valid = all([w.value.strip() for w in required_widgets])\n",
    "    \n",
    "    # Additional validation for HF dataset if push_to_hf is enabled\n",
    "    if push_to_hf_cb.value:\n",
    "        all_valid = all_valid and hf_dataset_repo_text.value.strip()\n",
    "    \n",
    "    start_btn.disabled = not all_valid\n",
    "    \n",
    "    if all_valid:\n",
    "        validation_status_text.value = \"<span style='color: green;'>All required fields are filled.</span>\"\n",
    "    else:\n",
    "        validation_status_text.value = \"<span style='color: red;'>Please fill all required fields marked with *.</span>\"\n",
    "\n",
    "# Authentication & Main Inputs\n",
    "header_auth = widgets.HTML(\"<div class='section-header'>Authentication & Setup</div>\")\n",
    "hf_token_widget = widgets.Password(\n",
    "    placeholder=\"hf_...\", \n",
    "    description=\"*HF Token:\",\n",
    ")\n",
    "hf_token_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Required. Your Hugging Face User Access Token (e.g., hf_xxx). Needs 'read' access for PyAnnote models. Get from hf.co/settings/tokens.\"\n",
    "))\n",
    "\n",
    "auth_box = widgets.HBox([hf_token_widget, hf_token_tooltip])\n",
    "auth_box.add_class(\"input-row\")\n",
    "\n",
    "# Input files\n",
    "header_input = widgets.HTML(\"<div class='section-header'>Input Files & Target Name</div>\")\n",
    "audio_dir_row, audio_dir_text = create_file_input_row(\n",
    "    \"*Audio Directory:\", \n",
    "    \"/content/drive/MyDrive/your_audio_folder\", \n",
    "    \"Path to the folder containing your input audio file(s) on Google Drive. This Colab version will process the first compatible audio found in this folder.\",\n",
    "    is_folder=True\n",
    ")\n",
    "\n",
    "reference_file_row, reference_file_text = create_file_input_row(\n",
    "    \"*Reference Audio:\", \n",
    "    \"/content/drive/MyDrive/your_reference.wav\", \n",
    "    \"Path to a clean reference audio (5-30s) of ONLY the target speaker on Google Drive.\",\n",
    "    is_folder=False\n",
    ")\n",
    "\n",
    "target_name_text = widgets.Text(\n",
    "    placeholder=\"e.g., JohnDoe\", \n",
    "    description=\"*Target Name:\"\n",
    ")\n",
    "target_name_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"A name for the target speaker (e.g., 'JohnDoe'). Used in output file/folder names.\"\n",
    "))\n",
    "target_name_box = widgets.HBox([target_name_text, target_name_tooltip])\n",
    "target_name_box.add_class(\"input-row\")\n",
    "\n",
    "output_base_dir_row, output_base_dir_text = create_file_input_row(\n",
    "    \"*Output Directory:\", \n",
    "    \"/content/drive/MyDrive/VoiceExtractor_Runs\", \n",
    "    \"Base GDrive folder where a new subfolder for this run's outputs will be created (e.g., `/content/drive/MyDrive/VoiceExtractor_Runs`).\",\n",
    "    is_folder=True\n",
    ")\n",
    "\n",
    "# Processing Options (Main)\n",
    "header_processing = widgets.HTML(\"<div class='section-header'>Basic Processing Options</div>\")\n",
    "\n",
    "output_sr_dd = widgets.Dropdown(\n",
    "    options=[16000, 22050, 24000, 44100, 48000],\n",
    "    value=44100,\n",
    "    description=\"Output Sample Rate:\"\n",
    ")\n",
    "output_sr_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Sample rate (Hz) for final output segments. 24000Hz is common for some ASR/TTS models.\"\n",
    "))\n",
    "output_sr_box = widgets.HBox([output_sr_dd, output_sr_tooltip])\n",
    "output_sr_box.add_class(\"input-row\")\n",
    "\n",
    "whisper_model_dd = widgets.Dropdown(\n",
    "    options=['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3'],\n",
    "    value='base.en',\n",
    "    description=\"Whisper Model:\"\n",
    ")\n",
    "whisper_model_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"OpenAI Whisper model for transcription. '.en' models are English-only. Larger models are more accurate but slower.\"\n",
    "))\n",
    "whisper_model_box = widgets.HBox([whisper_model_dd, whisper_model_tooltip])\n",
    "whisper_model_box.add_class(\"input-row\")\n",
    "\n",
    "language_text = widgets.Text(\n",
    "    value='en',\n",
    "    description=\"Language Code:\"\n",
    ")\n",
    "language_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Language code for Whisper (e.g., 'en', 'es', 'auto' for detection). Specifying is often more reliable.\"\n",
    "))\n",
    "language_box = widgets.HBox([language_text, language_tooltip])\n",
    "language_box.add_class(\"input-row\")\n",
    "\n",
    "# Advanced Options (Accordion)\n",
    "header_advanced = widgets.HTML(\"<div class='subsection-header'>Advanced Settings</div>\")\n",
    "\n",
    "min_duration_slider = widgets.FloatSlider(\n",
    "    value=1.0, \n",
    "    min=0.5, \n",
    "    max=10.0, \n",
    "    step=0.1,\n",
    "    description=\"Min Segment Duration:\"\n",
    ")\n",
    "min_duration_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Minimum duration (seconds) for a solo speaker segment to be kept.\"\n",
    "))\n",
    "min_duration_box = widgets.HBox([min_duration_slider, min_duration_tooltip])\n",
    "min_duration_box.add_class(\"input-row\")\n",
    "\n",
    "merge_gap_slider = widgets.FloatSlider(\n",
    "    value=0.25, \n",
    "    min=0.0, \n",
    "    max=2.0, \n",
    "    step=0.05,\n",
    "    description=\"Merge Gap:\"\n",
    ")\n",
    "merge_gap_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Maximum gap (seconds) to merge adjacent solo segments of the target speaker.\"\n",
    "))\n",
    "merge_gap_box = widgets.HBox([merge_gap_slider, merge_gap_tooltip])\n",
    "merge_gap_box.add_class(\"input-row\")\n",
    "\n",
    "verification_threshold_slider = widgets.FloatSlider(\n",
    "    value=0.69, \n",
    "    min=0.0, \n",
    "    max=1.0, \n",
    "    step=0.01,\n",
    "    description=\"Verification Threshold:\"\n",
    ")\n",
    "verification_threshold_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Speaker verification score (0-1). Higher is stricter. Segments below this are 'rejected'.\"\n",
    "))\n",
    "verification_threshold_box = widgets.HBox([verification_threshold_slider, verification_threshold_tooltip])\n",
    "verification_threshold_box.add_class(\"input-row\")\n",
    "\n",
    "concat_silence_slider = widgets.FloatSlider(\n",
    "    value=0.5, \n",
    "    min=0.0, \n",
    "    max=5.0, \n",
    "    step=0.1,\n",
    "    description=\"Concatenation Silence:\"\n",
    ")\n",
    "concat_silence_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Duration of silence (seconds) inserted between concatenated verified segments.\"\n",
    "))\n",
    "concat_silence_box = widgets.HBox([concat_silence_slider, concat_silence_tooltip])\n",
    "concat_silence_box.add_class(\"input-row\")\n",
    "\n",
    "skip_demucs_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Skip Demucs Vocal Separation\"\n",
    ")\n",
    "skip_demucs_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Check if audio is already clean/vocals-only to save time.\"\n",
    "))\n",
    "skip_demucs_box = widgets.HBox([skip_demucs_cb, skip_demucs_tooltip])\n",
    "skip_demucs_box.add_class(\"input-row\")\n",
    "\n",
    "disable_speechbrain_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Disable SpeechBrain Verification\"\n",
    ")\n",
    "disable_speechbrain_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Rely only on Resemblyzer for verification (faster, potentially less accurate).\"\n",
    "))\n",
    "disable_speechbrain_box = widgets.HBox([disable_speechbrain_cb, disable_speechbrain_tooltip])\n",
    "disable_speechbrain_box.add_class(\"input-row\")\n",
    "\n",
    "skip_rejected_transcripts_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Skip Transcribing Rejected Segments\"\n",
    ")\n",
    "skip_rejected_transcripts_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Saves time if you don't need transcripts for segments that failed verification or were too short.\"\n",
    "))\n",
    "skip_rejected_transcripts_box = widgets.HBox([skip_rejected_transcripts_cb, skip_rejected_transcripts_tooltip])\n",
    "skip_rejected_transcripts_box.add_class(\"input-row\")\n",
    "\n",
    "diar_model_dd = widgets.Dropdown(\n",
    "    options=[\"pyannote/speaker-diarization-3.1\", \"pyannote/speaker-diarization-3.0\"],\n",
    "    value=\"pyannote/speaker-diarization-3.1\",\n",
    "    description=\"Diarization Model:\"\n",
    ")\n",
    "diar_model_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"PyAnnote model for speaker diarization. Ensure you have accepted terms on Hugging Face.\"\n",
    "))\n",
    "diar_model_box = widgets.HBox([diar_model_dd, diar_model_tooltip])\n",
    "diar_model_box.add_class(\"input-row\")\n",
    "\n",
    "osd_model_dd = widgets.Dropdown(\n",
    "    options=[\"pyannote/segmentation-3.0\", \"pyannote/overlapped-speech-detection\"],\n",
    "    value=\"pyannote/segmentation-3.0\",\n",
    "    description=\"OSD Model:\"\n",
    ")\n",
    "osd_model_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"PyAnnote model for Overlapped Speech Detection. 'segmentation-3.0' is often used as a base. Ensure you have accepted terms.\"\n",
    "))\n",
    "osd_model_box = widgets.HBox([osd_model_dd, osd_model_tooltip])\n",
    "osd_model_box.add_class(\"input-row\")\n",
    "\n",
    "# Debug & File Management\n",
    "dry_run_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Dry Run (Process first 60s only)\"\n",
    ")\n",
    "dry_run_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Limits processing to the first minute of audio for quick testing.\"\n",
    "))\n",
    "dry_run_box = widgets.HBox([dry_run_cb, dry_run_tooltip])\n",
    "dry_run_box.add_class(\"input-row\")\n",
    "\n",
    "debug_log_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Enable Verbose Debug Logging\"\n",
    ")\n",
    "debug_log_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Outputs detailed logs for troubleshooting.\"\n",
    "))\n",
    "debug_log_box = widgets.HBox([debug_log_cb, debug_log_tooltip])\n",
    "debug_log_box.add_class(\"input-row\")\n",
    "\n",
    "keep_temp_files_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Keep Temporary Processing Files\"\n",
    ")\n",
    "keep_temp_files_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"Retains the `__tmp_processing` directory inside the run's output folder for inspection.\"\n",
    "))\n",
    "keep_temp_files_box = widgets.HBox([keep_temp_files_cb, keep_temp_files_tooltip])\n",
    "keep_temp_files_box.add_class(\"input-row\")\n",
    "\n",
    "# Output Handling & Export\n",
    "header_output = widgets.HTML(\"<div class='section-header'>Output Handling & Export</div>\")\n",
    "\n",
    "output_method_radio = widgets.RadioButtons(\n",
    "    options=[\n",
    "        \"Save ZIP to GDrive & Download to Computer\", \n",
    "        \"Download ZIP to Computer (No GDrive save of .zip)\", \n",
    "        \"Save ZIP to GDrive Only\"\n",
    "    ],\n",
    "    value=\"Save ZIP to GDrive & Download to Computer\",\n",
    "    description=\"Output Methods:\"\n",
    ")\n",
    "\n",
    "push_to_hf_cb = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Push Final Dataset to Hugging Face Hub\"\n",
    ")\n",
    "\n",
    "def toggle_hf_dataset_fields(change):\n",
    "    hf_dataset_repo_text.disabled = not change['new']\n",
    "    hf_dataset_private_cb.disabled = not change['new']\n",
    "    validate_inputs()\n",
    "\n",
    "push_to_hf_cb.observe(toggle_hf_dataset_fields, names='value')\n",
    "\n",
    "hf_dataset_repo_text = widgets.Text(\n",
    "    placeholder=\"your_username/dataset_name\",\n",
    "    description=\"HF Dataset Repo:\",\n",
    "    disabled=True\n",
    ")\n",
    "hf_dataset_repo_tooltip = widgets.HTML(create_tooltip_html(\n",
    "    \"HF Hub repository name. Will be created as private. Example: 'MyOrg/MyTargetSpeakerDataset'.\"\n",
    "))\n",
    "hf_dataset_repo_box = widgets.HBox([hf_dataset_repo_text, hf_dataset_repo_tooltip])\n",
    "hf_dataset_repo_box.add_class(\"input-row\")\n",
    "\n",
    "hf_dataset_private_cb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Make HF Dataset Private\",\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# Execution Control & Feedback\n",
    "validation_status_text = widgets.HTML(value=\"\")\n",
    "start_btn = widgets.Button(\n",
    "    description=\"🚀 Start Extraction\",\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    disabled=True,\n",
    "    layout={'width': '250px', 'height': '40px'}\n",
    ")\n",
    "start_btn.add_class(\"start-button\")\n",
    "\n",
    "overall_status_html = widgets.HTML(\n",
    "    value=\"<div class='status-message-container status-ready'>Status: Ready. Configure and click Start.</div>\"\n",
    ")\n",
    "\n",
    "log_output_widget = widgets.Output(\n",
    "    layout={'border': '1px solid #dedede', 'height': '400px', 'overflow_y': 'scroll', 'padding': '10px', 'margin_top':'10px'}\n",
    ")\n",
    "log_output_widget.add_class(\"log-area-container\")\n",
    "\n",
    "results_output_widget = widgets.Output(\n",
    "    layout={'margin_top':'10px'}\n",
    ")\n",
    "\n",
    "# Set up observers for input validation\n",
    "for w in [hf_token_widget, audio_dir_text, reference_file_text, target_name_text, output_base_dir_text]:\n",
    "    w.observe(lambda change: validate_inputs(), names='value')\n",
    "push_to_hf_cb.observe(lambda change: validate_inputs(), names='value')\n",
    "hf_dataset_repo_text.observe(lambda change: validate_inputs(), names='value')\n",
    "\n",
    "# Main execution function\n",
    "def run_extraction(button_click_event):\n",
    "    \"\"\"Main function to execute the Voice Extractor script.\"\"\"\n",
    "    log_output_widget.clear_output()\n",
    "    results_output_widget.clear_output()\n",
    "    \n",
    "    # Update UI\n",
    "    start_btn.disabled = True\n",
    "    start_btn.description = \"🔄 Processing...\"\n",
    "    start_btn.icon = \"spinner\"\n",
    "    overall_status_html.value = \"<div class='status-message-container status-processing'>Status: Initializing... Authenticating with Hugging Face...</div>\"\n",
    "    \n",
    "    # Hugging Face Login\n",
    "    try:\n",
    "        with log_output_widget:\n",
    "            print(f\"Authenticating with Hugging Face using token starting with: {hf_token_widget.value[:4]}...\")\n",
    "            login(token=hf_token_widget.value, add_to_git_credential=False)\n",
    "            print(\"✅ Authentication successful\")\n",
    "    except Exception as e:\n",
    "        overall_status_html.value = f\"<div class='status-message-container status-error'>Error: Hugging Face authentication failed.</div>\"\n",
    "        with log_output_widget:\n",
    "            print(f\"❌ Authentication Error: {str(e)}\")\n",
    "        start_btn.disabled = False\n",
    "        start_btn.description = \"🚀 Start Extraction\"\n",
    "        start_btn.icon = \"play\"\n",
    "        return\n",
    "    \n",
    "    # Input audio file discovery\n",
    "    try:\n",
    "        audio_dir = Path(audio_dir_text.value)\n",
    "        if not audio_dir.exists() or not audio_dir.is_dir():\n",
    "            raise FileNotFoundError(f\"Audio directory not found: {audio_dir}\")\n",
    "        \n",
    "        audio_files = []\n",
    "        for ext in ['.wav', '.mp3', '.m4a', '.flac']:\n",
    "            audio_files.extend(list(audio_dir.glob(f\"*{ext}\")))\n",
    "        \n",
    "        if not audio_files:\n",
    "            raise FileNotFoundError(f\"No audio files found in {audio_dir}\")\n",
    "        \n",
    "        input_audio_file = audio_files[0]\n",
    "        with log_output_widget:\n",
    "            print(f\"Found audio file: {input_audio_file}\")\n",
    "    except Exception as e:\n",
    "        overall_status_html.value = f\"<div class='status-message-container status-error'>Error: Could not find audio files.</div>\"\n",
    "        with log_output_widget:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "        start_btn.disabled = False\n",
    "        start_btn.description = \"🚀 Start Extraction\"\n",
    "        start_btn.icon = \"play\"\n",
    "        return\n",
    "    \n",
    "    # Construct the command\n",
    "    cmd_list = [\n",
    "        \"python\", \"Voice_Extractor/run_extractor.py\",\n",
    "        \"--input-audio\", f'\"{str(input_audio_file)}\"',\n",
    "        \"--reference-audio\", f'\"{str(reference_file_text.value)}\"',\n",
    "        \"--target-name\", target_name_text.value,\n",
    "        \"--output-base-dir\", f'\"{str(output_base_dir_text.value)}\"',\n",
    "        \"--token\", hf_token_widget.value,\n",
    "        \"--output-sr\", str(output_sr_dd.value),\n",
    "        \"--whisper-model\", whisper_model_dd.value,\n",
    "        \"--language\", language_text.value,\n",
    "        \"--min-duration\", str(min_duration_slider.value),\n",
    "        \"--merge-gap\", str(merge_gap_slider.value),\n",
    "        \"--verification-threshold\", str(verification_threshold_slider.value),\n",
    "        \"--concat-silence\", str(concat_silence_slider.value),\n",
    "        \"--diar-model\", diar_model_dd.value,\n",
    "        \"--osd-model\", osd_model_dd.value\n",
    "    ]\n",
    "    \n",
    "    # Add boolean flags\n",
    "    if skip_demucs_cb.value:\n",
    "        cmd_list.append(\"--skip-demucs\")\n",
    "    if disable_speechbrain_cb.value:\n",
    "        cmd_list.append(\"--disable-speechbrain\")\n",
    "    if skip_rejected_transcripts_cb.value:\n",
    "        cmd_list.append(\"--skip-rejected-transcripts\")\n",
    "    if dry_run_cb.value:\n",
    "        cmd_list.append(\"--dry-run\")\n",
    "    if debug_log_cb.value:\n",
    "        cmd_list.append(\"--debug\")\n",
    "    if keep_temp_files_cb.value:\n",
    "        cmd_list.append(\"--keep-temp-files\")\n",
    "    \n",
    "    # Update UI before starting process\n",
    "    overall_status_html.value = \"<div class='status-message-container status-processing'>Status: Running Voice Extractor script...</div>\"\n",
    "    \n",
    "    # Execute script\n",
    "    cmd_str = \" \".join(cmd_list)\n",
    "    with log_output_widget:\n",
    "        print(f\"Executing command: {cmd_str}\\n--- LOG START ---\")\n",
    "        process = subprocess.Popen(cmd_str, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                                  text=True, bufsize=1, universal_newlines=True, shell=True)\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "        exit_code = process.wait()\n",
    "    \n",
    "    # Post-execution processing\n",
    "    if exit_code == 0:\n",
    "        overall_status_html.value = \"<div class='status-message-container status-success'>Status: Voice extraction completed successfully!</div>\"\n",
    "        \n",
    "        # Determine the run output directory\n",
    "        run_output_dir_name = f\"{target_name_text.value.replace(' ', '_')}_{input_audio_file.stem}_SOLO_Split\"\n",
    "        actual_run_output_dir = Path(output_base_dir_text.value) / run_output_dir_name\n",
    "        \n",
    "        # Create ZIP archive\n",
    "        base_name_for_zip = actual_run_output_dir.parent / f\"{target_name_text.value.replace(' ', '_')}_dataset\"\n",
    "        zip_file_path = f\"{base_name_for_zip}.zip\"\n",
    "        \n",
    "        with log_output_widget:\n",
    "            print(f\"\\nCreating ZIP archive of results: {zip_file_path}\")\n",
    "            try:\n",
    "                shutil.make_archive(str(base_name_for_zip), 'zip', root_dir=actual_run_output_dir.parent, base_dir=actual_run_output_dir.name)\n",
    "                print(f\"✅ ZIP created successfully: {zip_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error creating ZIP: {str(e)}\")\n",
    "        \n",
    "        # Handle output based on selected method\n",
    "        output_method = output_method_radio.value\n",
    "        if \"Download to Computer\" in output_method:\n",
    "            with log_output_widget:\n",
    "                print(\"\\nPreparing to download ZIP file...\")\n",
    "                try:\n",
    "                    files.download(zip_file_path)\n",
    "                    print(\"✅ Download initiated. Check your browser downloads.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Download error: {str(e)}\")\n",
    "        \n",
    "        # Handle Hugging Face push if selected\n",
    "        if push_to_hf_cb.value:\n",
    "            with log_output_widget:\n",
    "                print(f\"\\nPreparing to push dataset to Hugging Face: {hf_dataset_repo_text.value}\")\n",
    "                try:\n",
    "                    from datasets import load_dataset, Audio\n",
    "                    \n",
    "                    # Find the verified transcripts CSV\n",
    "                    verified_csv_path = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))[0]\n",
    "                    \n",
    "                    print(f\"Loading dataset from {verified_csv_path}\")\n",
    "                    ds = load_dataset('csv', data_files={'train': str(verified_csv_path)}, \n",
    "                                      data_dir=str(actual_run_output_dir))\n",
    "                    \n",
    "                    # Cast audio column to Audio type\n",
    "                    ds = ds.cast_column('filename', Audio())\n",
    "                    \n",
    "                    print(f\"Pushing dataset to Hugging Face Hub: {hf_dataset_repo_text.value}\")\n",
    "                    ds.push_to_hub(\n",
    "                        hf_dataset_repo_text.value,\n",
    "                        private=hf_dataset_private_cb.value,\n",
    "                        token=hf_token_widget.value,\n",
    "                        embed_external_files=True\n",
    "                    )\n",
    "                    print(f\"✅ Dataset pushed successfully to https://huggingface.co/datasets/{hf_dataset_repo_text.value}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Hugging Face push error: {str(e)}\")\n",
    "        \n",
    "        # Display results preview\n",
    "        with results_output_widget:\n",
    "            print(\"## Extraction Results Summary\\n\")\n",
    "            \n",
    "            # Try to display the concatenated audio file\n",
    "            try:\n",
    "                concat_file = list(actual_run_output_dir.glob(\"concatenated_audio_solo/*.wav\"))[0]\n",
    "                print(f\"### Concatenated audio: {concat_file.name}\\n\")\n",
    "                display(Audio(str(concat_file)))\n",
    "            except (IndexError, FileNotFoundError):\n",
    "                print(\"### No concatenated audio file found\\n\")\n",
    "            \n",
    "            # Display transcript table\n",
    "            try:\n",
    "                transcript_csv = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))[0]\n",
    "                df = pd.read_csv(transcript_csv)\n",
    "                print(f\"\\n### Transcript sample (from {transcript_csv.name}):\\n\")\n",
    "                display(df.head())\n",
    "                print(f\"\\nTotal segments: {len(df)}\")\n",
    "            except (IndexError, FileNotFoundError):\n",
    "                print(\"\\n### No transcript CSV found\")\n",
    "            \n",
    "    else:\n",
    "        overall_status_html.value = f\"<div class='status-message-container status-error'>Error: Voice extraction failed with exit code {exit_code}.</div>\"\n",
    "        with log_output_widget:\n",
    "            print(f\"\\n❌ Process failed with exit code: {exit_code}\")\n",
    "    \n",
    "    # Re-enable UI\n",
    "    start_btn.disabled = False\n",
    "    start_btn.description = \"🚀 Start Extraction\"\n",
    "    start_btn.icon = \"play\"\n",
    "\n",
    "# Attach the execution function to the start button\n",
    "start_btn.on_click(run_extraction)\n",
    "\n",
    "# Create the advanced options accordion\n",
    "advanced_options = widgets.Accordion(\n",
    "    children=[\n",
    "        widgets.VBox([\n",
    "            min_duration_box,\n",
    "            merge_gap_box,\n",
    "            verification_threshold_box,\n",
    "            concat_silence_box,\n",
    "            skip_demucs_box, \n",
    "            disable_speechbrain_box,\n",
    "            skip_rejected_transcripts_box\n",
    "        ]),\n",
    "        widgets.VBox([\n",
    "            diar_model_box,\n",
    "            osd_model_box\n",
    "        ]),\n",
    "        widgets.VBox([\n",
    "            dry_run_box,\n",
    "            debug_log_box,\n",
    "            keep_temp_files_box\n",
    "        ])\n",
    "    ],\n",
    "    titles=('Segment Parameters', 'Model Options', 'Debug & Temp Files')\n",
    ")\n",
    "\n",
    "# Layout\n",
    "main_layout = widgets.VBox([\n",
    "    widgets.HTML(\"<h1 style='text-align:center; color:#1A73E8;'>Voice Extractor - Google Colab Interface</h1>\"),\n",
    "    widgets.HTML(\"<p style='text-align:center;'>Extract solo voice segments of a target speaker from multi-speaker recordings</p>\"),\n",
    "    \n",
    "    header_auth,\n",
    "    auth_box,\n",
    "    \n",
    "    header_input,\n",
    "    audio_dir_row,\n",
    "    reference_file_row,\n",
    "    target_name_box,\n",
    "    output_base_dir_row,\n",
    "    \n",
    "    header_processing,\n",
    "    output_sr_box,\n",
    "    whisper_model_box,\n",
    "    language_box,\n",
    "    \n",
    "    header_advanced,\n",
    "    advanced_options,\n",
    "    \n",
    "    header_output,\n",
    "    output_method_radio,\n",
    "    widgets.VBox([push_to_hf_cb, hf_dataset_repo_box, hf_dataset_private_cb]),\n",
    "    \n",
    "    widgets.HBox([start_btn, validation_status_text]),\n",
    "    overall_status_html,\n",
    "    widgets.HTML(\"<div class='section-header'>Processing Log</div>\"),\n",
    "    log_output_widget,\n",
    "    widgets.HTML(\"<div class='section-header'>Results</div>\"),\n",
    "    results_output_widget\n",
    "])\n",
    "\n",
    "# Call validate_inputs once to set initial state\n",
    "validate_inputs()\n",
    "\n",
    "# Display the layout\n",
    "display(main_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8137fb8",
   "metadata": {},
   "source": [
    "# Voice Extractor - Usage Instructions\n",
    "\n",
    "This notebook provides a graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, which identifies, isolates, and transcribes clean solo segments of a target speaker from multi-speaker audio recordings.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Authentication**: Enter your HuggingFace User Access Token. This is required to access PyAnnote models.\n",
    "2. **Input Files**:\n",
    "   - Specify the folder containing your audio (first compatible audio file will be processed)\n",
    "   - Select a clean reference audio of ONLY your target speaker (5-30 seconds)\n",
    "   - Enter a name for your target speaker\n",
    "   - Choose an output directory for results\n",
    "3. **Processing Options**: Configure sample rate, transcription model, and other settings\n",
    "4. **Advanced Options**: Fine-tune segment parameters, model selection, and debug settings\n",
    "5. **Output Handling**: Choose how to save results and optionally push to Hugging Face\n",
    "6. **Start Processing**: Click the \"Start Extraction\" button when all required fields are filled\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- You need to accept the terms of use for the following PyAnnote models on Hugging Face:\n",
    "  - [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "  - [pyannote/overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
    "  - [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)\n",
    "- For optimal results, provide a clean reference audio with only the target speaker's voice\n",
    "- The \"Dry Run\" option is helpful for testing as it processes only the first 60 seconds\n",
    "- GPU acceleration is automatically used when available\n",
    "\n",
    "For more detailed documentation, visit the [Voice Extractor GitHub repository](https://github.com/ReisCook/Voice_Extractor).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
