{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ee9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice Extractor - Fixed Implementation with proper language handling\n",
    "import os\n",
    "\n",
    "# Skip clone if folder already exists\n",
    "if not os.path.exists('Voice_Extractor'):\n",
    "    !git clone -q https://github.com/ReisCook/Voice_Extractor.git\n",
    "\n",
    "# Install requirements directly from repo\n",
    "!pip install -q -r Voice_Extractor/requirements.txt\n",
    "!pip install -q ipywidgets pandas matplotlib huggingface_hub datasets\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from IPython.display import display, Audio, clear_output, HTML\n",
    "from google.colab import files\n",
    "from huggingface_hub import login\n",
    "from pathlib import Path\n",
    "\n",
    "# CSS for UI\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    .widget-label {max-width: none !important; width: auto !important; overflow: visible !important; white-space: normal !important;}\n",
    "    .widget-checkbox > .widget-label {min-width: 250px !important;}\n",
    "    .section-header {font-size: 1.3em; font-weight: bold; color: #1A73E8; margin-top: 20px; \n",
    "                    margin-bottom: 15px; padding-bottom: 5px; border-bottom: 2px solid #1A73E8;}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Create UI components\n",
    "def create_section(title):\n",
    "    return widgets.HTML(f\"<div class='section-header'>{title}</div>\")\n",
    "\n",
    "def create_text_input(description, placeholder=\"\", required=False, password=False):\n",
    "    widget_class = widgets.Password if password else widgets.Text\n",
    "    return widget_class(\n",
    "        description=f\"{'*' if required else ''}{description}:\",\n",
    "        placeholder=placeholder,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_dropdown(description, options, default_value=None):\n",
    "    return widgets.Dropdown(\n",
    "        description=f\"{description}:\",\n",
    "        options=options,\n",
    "        value=default_value or options[0],\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_slider(description, min_val, max_val, step, default):\n",
    "    return widgets.FloatSlider(\n",
    "        description=f\"{description}:\",\n",
    "        min=min_val, max=max_val, step=step, value=default,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_checkbox(description):\n",
    "    return widgets.Checkbox(\n",
    "        description=description,\n",
    "        layout=widgets.Layout(width='auto')\n",
    "    )\n",
    "\n",
    "# Create sections\n",
    "auth_section = create_section(\"Authentication & Setup\")\n",
    "input_section = create_section(\"Input Files & Target Name\")\n",
    "processing_section = create_section(\"Basic Processing Options\")\n",
    "advanced_section = create_section(\"Advanced Settings\")\n",
    "output_section = create_section(\"Output Handling & Export\")\n",
    "\n",
    "# Create inputs\n",
    "hf_token = create_text_input(\"HF Token\", \"hf_...\", required=True, password=True)\n",
    "audio_dir = create_text_input(\"Audio Directory\", \"/content/drive/MyDrive/your_audio_folder\", required=True)\n",
    "reference_file = create_text_input(\"Reference Audio\", \"/content/drive/MyDrive/your_reference.wav\", required=True)\n",
    "target_name = create_text_input(\"Target Name\", \"e.g., JohnDoe\", required=True)\n",
    "output_dir = create_text_input(\"Output Directory\", \"/content/drive/MyDrive/VoiceExtractor_Runs\", required=True)\n",
    "\n",
    "# Processing options\n",
    "output_sr = create_dropdown(\"Output Sample Rate\", [16000, 22050, 24000, 44100, 48000], 44100)\n",
    "whisper_model = create_dropdown(\n",
    "    \"Whisper Model\", \n",
    "    ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3'],\n",
    "    'base.en'\n",
    ")\n",
    "language = create_text_input(\"Language Code\", \"en\")\n",
    "\n",
    "# Advanced options\n",
    "min_duration = create_slider(\"Min Segment Duration\", 0.5, 10.0, 0.1, 1.0)\n",
    "merge_gap = create_slider(\"Merge Gap\", 0.0, 2.0, 0.05, 0.25)\n",
    "verification_threshold = create_slider(\"Verification Threshold\", 0.0, 1.0, 0.01, 0.69)\n",
    "concat_silence = create_slider(\"Concatenation Silence\", 0.0, 5.0, 0.1, 0.5)\n",
    "skip_demucs = create_checkbox(\"Skip Demucs Vocal Separation\")\n",
    "disable_speechbrain = create_checkbox(\"Disable SpeechBrain Verification\")\n",
    "skip_rejected_transcripts = create_checkbox(\"Skip Transcribing Rejected Segments\")\n",
    "diar_model = create_dropdown(\n",
    "    \"Diarization Model\", \n",
    "    [\"pyannote/speaker-diarization-3.1\", \"pyannote/speaker-diarization-3.0\"],\n",
    "    \"pyannote/speaker-diarization-3.1\"\n",
    ")\n",
    "osd_model = create_dropdown(\n",
    "    \"OSD Model\", \n",
    "    [\"pyannote/overlapped-speech-detection\", \"pyannote/segmentation-3.0\"],\n",
    "    \"pyannote/overlapped-speech-detection\"\n",
    ")\n",
    "dry_run = create_checkbox(\"Dry Run (Process first 60s only)\")\n",
    "debug_log = create_checkbox(\"Enable Verbose Debug Logging\")\n",
    "keep_temp_files = create_checkbox(\"Keep Temporary Processing Files\")\n",
    "\n",
    "# Output options\n",
    "output_method = create_dropdown(\n",
    "    \"Output Methods\", \n",
    "    [\n",
    "        \"Save ZIP to GDrive & Download to Computer\", \n",
    "        \"Download ZIP to Computer (No GDrive save of .zip)\", \n",
    "        \"Save ZIP to GDrive Only\"\n",
    "    ]\n",
    ")\n",
    "push_to_hf = create_checkbox(\"Push Final Dataset to Hugging Face Hub\")\n",
    "hf_dataset_repo = create_text_input(\"HF Dataset Repo\", \"your_username/dataset_name\")\n",
    "hf_dataset_private = create_checkbox(\"Make HF Dataset Private\")\n",
    "hf_dataset_private.value = True\n",
    "hf_dataset_repo.disabled = True\n",
    "hf_dataset_private.disabled = True\n",
    "\n",
    "# Status elements\n",
    "status_message = widgets.HTML(\"<div style='margin-top:15px; text-align:center; padding:10px; background:#e0e0e0; border-radius:5px;'>Status: Ready. Configure and click Start.</div>\")\n",
    "validation_message = widgets.HTML()\n",
    "log_output = widgets.Output(layout={'height': '400px', 'overflow_y': 'scroll', 'border': '1px solid #ccc', 'margin-top': '10px'})\n",
    "results_output = widgets.Output(layout={'margin-top': '10px'})\n",
    "\n",
    "# Toggle HF dataset fields\n",
    "def toggle_hf_fields(change):\n",
    "    hf_dataset_repo.disabled = not change['new']\n",
    "    hf_dataset_private.disabled = not change['new']\n",
    "    validate_inputs()\n",
    "\n",
    "push_to_hf.observe(toggle_hf_fields, names='value')\n",
    "\n",
    "# Run button\n",
    "start_btn = widgets.Button(\n",
    "    description=\"🚀 Start Extraction\",\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    disabled=True,\n",
    "    layout={'width': '250px', 'height': '40px', 'margin': '10px 0'}\n",
    ")\n",
    "\n",
    "# Validation function\n",
    "def validate_inputs(*args):\n",
    "    required_fields = [hf_token, audio_dir, reference_file, target_name, output_dir]\n",
    "    all_valid = all(w.value.strip() for w in required_fields)\n",
    "    \n",
    "    if push_to_hf.value:\n",
    "        all_valid = all_valid and hf_dataset_repo.value.strip()\n",
    "    \n",
    "    start_btn.disabled = not all_valid\n",
    "    validation_message.value = \"<span style='color: green;'>All required fields are filled.</span>\" if all_valid else \"<span style='color: red;'>Please fill all required fields marked with *.</span>\"\n",
    "\n",
    "# Add observers\n",
    "for w in [hf_token, audio_dir, reference_file, target_name, output_dir, hf_dataset_repo]:\n",
    "    w.observe(lambda change: validate_inputs(), names='value')\n",
    "\n",
    "# Main function to run extraction\n",
    "def run_extraction(b):\n",
    "    log_output.clear_output()\n",
    "    results_output.clear_output()\n",
    "    \n",
    "    # Update UI\n",
    "    start_btn.disabled = True\n",
    "    start_btn.description = \"🔄 Processing...\"\n",
    "    start_btn.icon = \"spinner\"\n",
    "    status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#fff3cd; color:#856404; border:1px solid #ffeeba; border-radius:5px;'>Status: Initializing... Authenticating with Hugging Face...</div>\"\n",
    "    \n",
    "    # Login to HuggingFace\n",
    "    with log_output:\n",
    "        try:\n",
    "            print(f\"Authenticating with Hugging Face using token starting with: {hf_token.value[:4]}...\")\n",
    "            login(token=hf_token.value, add_to_git_credential=False)\n",
    "            print(\"✅ Authentication successful\")\n",
    "            \n",
    "            # Find audio files\n",
    "            audio_dir_path = Path(audio_dir.value)\n",
    "            if not audio_dir_path.exists() or not audio_dir_path.is_dir():\n",
    "                raise FileNotFoundError(f\"Audio directory not found: {audio_dir_path}\")\n",
    "            \n",
    "            audio_files = []\n",
    "            for ext in ['.wav', '.mp3', '.m4a', '.flac']:\n",
    "                audio_files.extend(list(audio_dir_path.glob(f\"*{ext}\")))\n",
    "            \n",
    "            if not audio_files:\n",
    "                raise FileNotFoundError(f\"No audio files found in {audio_dir_path}\")\n",
    "            \n",
    "            input_audio_file = audio_files[0]\n",
    "            print(f\"Found audio file: {input_audio_file}\")\n",
    "            \n",
    "            # Build command\n",
    "            cmd_list = [\n",
    "                \"python\", \"Voice_Extractor/run_extractor.py\",\n",
    "                \"--input-audio\", f'\"{str(input_audio_file)}\"',\n",
    "                \"--reference-audio\", f'\"{str(reference_file.value)}\"',\n",
    "                \"--target-name\", target_name.value,\n",
    "                \"--output-base-dir\", f'\"{str(output_dir.value)}\"',\n",
    "                \"--token\", hf_token.value,\n",
    "                \"--output-sr\", str(output_sr.value),\n",
    "                \"--whisper-model\", whisper_model.value,\n",
    "                \"--min-duration\", str(min_duration.value),\n",
    "                \"--merge-gap\", str(merge_gap.value),\n",
    "                \"--verification-threshold\", str(verification_threshold.value),\n",
    "                \"--concat-silence\", str(concat_silence.value),\n",
    "                \"--diar-model\", diar_model.value,\n",
    "                \"--osd-model\", osd_model.value\n",
    "            ]\n",
    "            \n",
    "            # Only add language parameter if it's not empty\n",
    "            if language.value.strip():\n",
    "                cmd_list.extend([\"--language\", language.value.strip()])\n",
    "            \n",
    "            # Add boolean flags\n",
    "            if skip_demucs.value: cmd_list.append(\"--skip-demucs\")\n",
    "            if disable_speechbrain.value: cmd_list.append(\"--disable-speechbrain\")\n",
    "            if skip_rejected_transcripts.value: cmd_list.append(\"--skip-rejected-transcripts\")\n",
    "            if dry_run.value: cmd_list.append(\"--dry-run\")\n",
    "            if debug_log.value: cmd_list.append(\"--debug\")\n",
    "            if keep_temp_files.value: cmd_list.append(\"--keep-temp-files\")\n",
    "            \n",
    "            # Execute command\n",
    "            status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#fff3cd; color:#856404; border:1px solid #ffeeba; border-radius:5px;'>Status: Running Voice Extractor script...</div>\"\n",
    "            cmd_str = \" \".join(cmd_list)\n",
    "            print(f\"Executing command: {cmd_str}\\n--- LOG START ---\")\n",
    "            \n",
    "            process = subprocess.Popen(cmd_str, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                                     text=True, bufsize=1, universal_newlines=True, shell=True)\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "            exit_code = process.wait()\n",
    "            \n",
    "            # Handle result\n",
    "            if exit_code == 0:\n",
    "                status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#d4edda; color:#155724; border:1px solid #c3e6cb; border-radius:5px;'>Status: Voice extraction completed successfully!</div>\"\n",
    "                \n",
    "                # Process outputs\n",
    "                run_output_dir_name = f\"{target_name.value.replace(' ', '_')}_{input_audio_file.stem}_SOLO_Split\"\n",
    "                actual_run_output_dir = Path(output_dir.value) / run_output_dir_name\n",
    "                \n",
    "                # Create ZIP\n",
    "                base_name_for_zip = actual_run_output_dir.parent / f\"{target_name.value.replace(' ', '_')}_dataset\"\n",
    "                zip_file_path = f\"{base_name_for_zip}.zip\"\n",
    "                \n",
    "                print(f\"\\nCreating ZIP archive of results: {zip_file_path}\")\n",
    "                shutil.make_archive(str(base_name_for_zip), 'zip', root_dir=actual_run_output_dir.parent, base_dir=actual_run_output_dir.name)\n",
    "                print(f\"✅ ZIP created successfully: {zip_file_path}\")\n",
    "                \n",
    "                # Download if requested\n",
    "                if \"Download to Computer\" in output_method.value:\n",
    "                    print(\"\\nPreparing to download ZIP file...\")\n",
    "                    files.download(zip_file_path)\n",
    "                    print(\"✅ Download initiated. Check your browser downloads.\")\n",
    "                \n",
    "                # Push to HF if requested\n",
    "                if push_to_hf.value:\n",
    "                    print(f\"\\nPreparing to push dataset to Hugging Face: {hf_dataset_repo.value}\")\n",
    "                    from datasets import load_dataset, Audio\n",
    "                    \n",
    "                    verified_csv_path = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))[0]\n",
    "                    print(f\"Loading dataset from {verified_csv_path}\")\n",
    "                    \n",
    "                    ds = load_dataset('csv', data_files={'train': str(verified_csv_path)}, \n",
    "                                    data_dir=str(actual_run_output_dir))\n",
    "                    ds = ds.cast_column('filename', Audio())\n",
    "                    \n",
    "                    print(f\"Pushing dataset to Hugging Face Hub: {hf_dataset_repo.value}\")\n",
    "                    ds.push_to_hub(\n",
    "                        hf_dataset_repo.value,\n",
    "                        private=hf_dataset_private.value,\n",
    "                        token=hf_token.value,\n",
    "                        embed_external_files=True\n",
    "                    )\n",
    "                    print(f\"✅ Dataset pushed successfully to https://huggingface.co/datasets/{hf_dataset_repo.value}\")\n",
    "                \n",
    "                # Show results\n",
    "                with results_output:\n",
    "                    print(\"## Extraction Results Summary\\n\")\n",
    "                    \n",
    "                    try:\n",
    "                        concat_file = list(actual_run_output_dir.glob(\"concatenated_audio_solo/*.wav\"))[0]\n",
    "                        print(f\"### Concatenated audio: {concat_file.name}\\n\")\n",
    "                        display(Audio(str(concat_file)))\n",
    "                    except (IndexError, FileNotFoundError):\n",
    "                        print(\"### No concatenated audio file found\\n\")\n",
    "                    \n",
    "                    try:\n",
    "                        transcript_csv = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))[0]\n",
    "                        df = pd.read_csv(transcript_csv)\n",
    "                        print(f\"\\n### Transcript sample (from {transcript_csv.name}):\\n\")\n",
    "                        display(df.head())\n",
    "                        print(f\"\\nTotal segments: {len(df)}\")\n",
    "                    except (IndexError, FileNotFoundError):\n",
    "                        print(\"\\n### No transcript CSV found\")\n",
    "            else:\n",
    "                status_message.value = f\"<div style='margin-top:15px; text-align:center; padding:10px; background:#f8d7da; color:#721c24; border:1px solid #f5c6cb; border-radius:5px;'>Error: Voice extraction failed with exit code {exit_code}.</div>\"\n",
    "                print(f\"\\n❌ Process failed with exit code: {exit_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            status_message.value = f\"<div style='margin-top:15px; text-align:center; padding:10px; background:#f8d7da; color:#721c24; border:1px solid #f5c6cb; border-radius:5px;'>Error: {str(e)}</div>\"\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "    \n",
    "    # Re-enable UI\n",
    "    start_btn.disabled = False\n",
    "    start_btn.description = \"🚀 Start Extraction\"\n",
    "    start_btn.icon = \"play\"\n",
    "    validate_inputs()\n",
    "\n",
    "# Attach event to button\n",
    "start_btn.on_click(run_extraction)\n",
    "\n",
    "# Group related settings\n",
    "segment_params = widgets.VBox([min_duration, merge_gap, verification_threshold, concat_silence, \n",
    "                             skip_demucs, disable_speechbrain, skip_rejected_transcripts])\n",
    "model_params = widgets.VBox([diar_model, osd_model])\n",
    "debug_params = widgets.VBox([dry_run, debug_log, keep_temp_files])\n",
    "\n",
    "# Create accordion for advanced settings\n",
    "advanced_accordion = widgets.Accordion(\n",
    "    children=[segment_params, model_params, debug_params],\n",
    "    titles=('Segment Parameters', 'Model Options', 'Debug & Temp Files')\n",
    ")\n",
    "\n",
    "# Create final layout\n",
    "main_layout = widgets.VBox([\n",
    "    widgets.HTML(\"<h1 style='text-align:center; color:#1A73E8;'>Voice Extractor - Google Colab Interface</h1>\"),\n",
    "    widgets.HTML(\"<p style='text-align:center;'>Extract solo voice segments of a target speaker from multi-speaker recordings</p>\"),\n",
    "    \n",
    "    auth_section,\n",
    "    hf_token,\n",
    "    \n",
    "    input_section,\n",
    "    audio_dir,\n",
    "    reference_file,\n",
    "    target_name,\n",
    "    output_dir,\n",
    "    \n",
    "    processing_section,\n",
    "    output_sr,\n",
    "    whisper_model,\n",
    "    language,\n",
    "    \n",
    "    advanced_section,\n",
    "    advanced_accordion,\n",
    "    \n",
    "    output_section,\n",
    "    output_method,\n",
    "    push_to_hf,\n",
    "    hf_dataset_repo,\n",
    "    hf_dataset_private,\n",
    "    \n",
    "    widgets.HBox([start_btn, validation_message]),\n",
    "    status_message,\n",
    "    create_section(\"Processing Log\"),\n",
    "    log_output,\n",
    "    create_section(\"Results\"),\n",
    "    results_output\n",
    "])\n",
    "\n",
    "# Initialize validation\n",
    "validate_inputs()\n",
    "\n",
    "# Display the UI\n",
    "display(main_layout)\n",
    "print(\"Voice Extractor interface ready to use with default OSD Model set to overlapped-speech-detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8137fb8",
   "metadata": {},
   "source": [
    "# Voice Extractor - Usage Instructions\n",
    "\n",
    "This notebook provides a graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, which identifies, isolates, and transcribes clean solo segments of a target speaker from multi-speaker audio recordings.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Authentication**: Enter your HuggingFace User Access Token. This is required to access PyAnnote models.\n",
    "2. **Input Files**:\n",
    "   - Specify the folder containing your audio (first compatible audio file will be processed)\n",
    "   - Select a clean reference audio of ONLY your target speaker (5-30 seconds)\n",
    "   - Enter a name for your target speaker\n",
    "   - Choose an output directory for results\n",
    "3. **Processing Options**: Configure sample rate, transcription model, and other settings\n",
    "4. **Advanced Options**: Fine-tune segment parameters, model selection, and debug settings\n",
    "5. **Output Handling**: Choose how to save results and optionally push to Hugging Face\n",
    "6. **Start Processing**: Click the \"Start Extraction\" button when all required fields are filled\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- You need to accept the terms of use for the following PyAnnote models on Hugging Face:\n",
    "  - [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "  - [pyannote/overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
    "  - [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)\n",
    "- For optimal results, provide a clean reference audio with only the target speaker's voice\n",
    "- The \"Dry Run\" option is helpful for testing as it processes only the first 60 seconds\n",
    "- GPU acceleration is automatically used when available\n",
    "\n",
    "For more detailed documentation, visit the [Voice Extractor GitHub repository](https://github.com/ReisCook/Voice_Extractor).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
