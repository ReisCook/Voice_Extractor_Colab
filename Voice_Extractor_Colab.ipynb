{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ee9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Skip clone if folder already exists\n",
    "if not os.path.exists('Voice_Extractor'):\n",
    "    !git clone -q https://github.com/ReisCook/Voice_Extractor.git\n",
    "\n",
    "# Install requirements directly from repo\n",
    "!pip uninstall -y fastai\n",
    "!pip install -q -r Voice_Extractor/requirements.txt\n",
    "!pip install -q ipywidgets pandas matplotlib huggingface_hub datasets\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Audio # Added Audio here for earlier availability if needed\n",
    "from google.colab import files\n",
    "from huggingface_hub import login\n",
    "from pathlib import Path\n",
    "\n",
    "# Removed empty HTML display call that was here\n",
    "\n",
    "# Create UI components\n",
    "def create_section(title):\n",
    "    return widgets.HTML(f\"<h3>{title}</h3>\") # Made title a bit more prominent\n",
    "\n",
    "def create_text_input(description, placeholder=\"\", required=False, password=False):\n",
    "    widget_class = widgets.Password if password else widgets.Text\n",
    "    return widget_class(\n",
    "        description=f\"{'*' if required else ''}{description}:\",\n",
    "        placeholder=placeholder,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_dropdown(description, options, default_value=None):\n",
    "    # Ensure default_value is one of the options, otherwise use the first option\n",
    "    actual_default = default_value if default_value in options else (options[0] if options else None)\n",
    "    return widgets.Dropdown(\n",
    "        description=f\"{description}:\",\n",
    "        options=options,\n",
    "        value=actual_default,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_slider(description, min_val, max_val, step, default):\n",
    "    return widgets.FloatSlider(\n",
    "        description=f\"{description}:\",\n",
    "        min=min_val, max=max_val, step=step, value=default,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_checkbox(description, initial_value=False):\n",
    "    return widgets.Checkbox(\n",
    "        description=description,\n",
    "        value=initial_value,\n",
    "        layout=widgets.Layout(width='auto')\n",
    "    )\n",
    "\n",
    "# Create sections\n",
    "auth_section = create_section(\"Authentication & Setup\")\n",
    "input_section = create_section(\"Input Files & Target Name\")\n",
    "processing_section = create_section(\"Basic Processing Options\")\n",
    "performance_section = create_section(\"Performance & Memory Options\")\n",
    "advanced_section = create_section(\"Advanced Settings\")\n",
    "output_section = create_section(\"Output Handling & Export\")\n",
    "\n",
    "# Create warning about memory usage\n",
    "memory_warning = widgets.HTML(\n",
    "    \"<p style='color:orange;'>‚ö†Ô∏è 'Skip Demucs' is enabled by default to prevent memory errors in Colab. Disable only if processing small files or if your audio is already vocally isolated.</p>\"\n",
    ")\n",
    "\n",
    "# Create inputs\n",
    "hf_token = create_text_input(\"HF Token\", \"hf_...\", required=True, password=True)\n",
    "audio_dir = create_text_input(\"Audio Directory\", \"/content/drive/MyDrive/your_audio_folder\", required=True)\n",
    "reference_file = create_text_input(\"Reference Audio\", \"/content/drive/MyDrive/your_reference.wav\", required=True)\n",
    "target_name = create_text_input(\"Target Name\", \"e.g., JohnDoe\", required=True)\n",
    "output_dir = create_text_input(\"Output Directory\", \"/content/drive/MyDrive/VoiceExtractor_Runs\", required=True)\n",
    "\n",
    "# Processing options\n",
    "output_sr = create_dropdown(\"Output Sample Rate\", [16000, 22050, 24000, 44100, 48000], 24000)\n",
    "whisper_model = create_dropdown(\n",
    "    \"Whisper Model\", \n",
    "    ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3'],\n",
    "    'large-v3'\n",
    ")\n",
    "language = create_text_input(\"Language Code (e.g., en, es)\", \"en\")\n",
    "\n",
    "# Performance options - make Skip Demucs enabled by default\n",
    "skip_demucs = create_checkbox(\"Skip Demucs Vocal Separation\", initial_value=True)\n",
    "skip_demucs_description = widgets.HTML(\n",
    "    \"<small>Recommended for Colab. If your audio already has isolated vocals, keep this checked.</small>\"\n",
    ")\n",
    "\n",
    "# Advanced options\n",
    "min_duration = create_slider(\"Min Segment Duration (s)\", 0.5, 10.0, 0.1, 1.0)\n",
    "merge_gap = create_slider(\"Merge Gap (s)\", 0.0, 2.0, 0.05, 0.25)\n",
    "verification_threshold = create_slider(\"Verification Threshold (0-1)\", 0.0, 1.0, 0.01, 0.69)\n",
    "concat_silence = create_slider(\"Concatenation Silence (s)\", 0.0, 5.0, 0.1, 0.5)\n",
    "disable_speechbrain = create_checkbox(\"Disable SpeechBrain Verification\")\n",
    "skip_rejected_transcripts = create_checkbox(\"Skip Transcribing Rejected Segments\")\n",
    "diar_model = create_dropdown(\n",
    "    \"Diarization Model\", \n",
    "    [\"pyannote/speaker-diarization-3.1\", \"pyannote/speaker-diarization-3.0\"],\n",
    "    \"pyannote/speaker-diarization-3.1\"\n",
    ")\n",
    "osd_model = create_dropdown(\n",
    "    \"OSD Model\", \n",
    "    [\"pyannote/overlapped-speech-detection\"],\n",
    "    \"pyannote/overlapped-speech-detection\"\n",
    ")\n",
    "dry_run = create_checkbox(\"Dry Run (Process first 60s only)\")\n",
    "debug_log = create_checkbox(\"Enable Verbose Debug Logging\")\n",
    "keep_temp_files = create_checkbox(\"Keep Temporary Processing Files\")\n",
    "\n",
    "# Output options\n",
    "output_method = create_dropdown(\n",
    "    \"Output Methods\", \n",
    "    [\n",
    "        \"Save ZIP to GDrive & Download to Computer\", \n",
    "        \"Download ZIP to Computer (No GDrive save of .zip)\", \n",
    "        \"Save ZIP to GDrive Only\"\n",
    "    ],\n",
    "    \"Save ZIP to GDrive & Download to Computer\"\n",
    ")\n",
    "push_to_hf = create_checkbox(\"Push Final Dataset to Hugging Face Hub\")\n",
    "hf_dataset_repo = create_text_input(\"HF Dataset Repo\", \"your_username/dataset_name\")\n",
    "hf_dataset_private = create_checkbox(\"Make HF Dataset Private\", initial_value=True)\n",
    "hf_dataset_repo.disabled = True\n",
    "hf_dataset_private.disabled = True\n",
    "\n",
    "# Status elements\n",
    "status_message = widgets.HTML(\"Status: Ready. Configure and click Start.\")\n",
    "validation_message = widgets.HTML()\n",
    "log_output = widgets.Output(layout={'height': '400px', 'overflow_y': 'scroll', 'border': '1px solid #ccc', 'margin_top': '10px'})\n",
    "results_output = widgets.Output(layout={'margin_top': '10px'})\n",
    "\n",
    "# Toggle HF dataset fields\n",
    "def toggle_hf_fields(change):\n",
    "    hf_dataset_repo.disabled = not change.new # Direct attribute access for 'new' value\n",
    "    hf_dataset_private.disabled = not change.new\n",
    "    validate_inputs()\n",
    "\n",
    "push_to_hf.observe(toggle_hf_fields, names='value')\n",
    "\n",
    "# Run button\n",
    "start_btn = widgets.Button(\n",
    "    description=\"üöÄ Start Extraction\",\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    disabled=True,\n",
    "    layout={'width': '250px', 'height': '40px', 'margin': '10px 0'}\n",
    ")\n",
    "\n",
    "# Validation function\n",
    "def validate_inputs(*args): # *args catches any observer event data\n",
    "    required_field_widgets = [hf_token, audio_dir, reference_file, target_name, output_dir]\n",
    "    all_valid = all(w.value.strip() for w in required_field_widgets)\n",
    "    \n",
    "    if push_to_hf.value:\n",
    "        all_valid = all_valid and hf_dataset_repo.value.strip()\n",
    "    \n",
    "    start_btn.disabled = not all_valid\n",
    "    if all_valid:\n",
    "        validation_message.value = \"<p style='color:green;'>All required fields are filled.</p>\"\n",
    "    else:\n",
    "        validation_message.value = \"<p style='color:red;'>Please fill all required fields marked with *.</p>\"\n",
    "\n",
    "# Add observers (using direct function reference as suggested and previously implemented)\n",
    "for w in [hf_token, audio_dir, reference_file, target_name, output_dir, hf_dataset_repo]:\n",
    "    w.observe(validate_inputs, names='value')\n",
    "\n",
    "# Main function to run extraction\n",
    "def run_extraction(b): # b is the button instance from on_click\n",
    "    log_output.clear_output()\n",
    "    results_output.clear_output()\n",
    "    \n",
    "    # Update UI\n",
    "    start_btn.disabled = True\n",
    "    start_btn.description = \"üîÑ Processing...\"\n",
    "    start_btn.icon = \"spinner\"\n",
    "    status_message.value = \"Status: Initializing... Authenticating with Hugging Face...\"\n",
    "    \n",
    "    with log_output:\n",
    "        try:\n",
    "            print(f\"Authenticating with Hugging Face using token starting with: {hf_token.value[:4]}...\")\n",
    "            login(token=hf_token.value, add_to_git_credential=False)\n",
    "            print(\"‚úÖ Authentication successful\")\n",
    "            \n",
    "            audio_dir_path = Path(audio_dir.value)\n",
    "            if not audio_dir_path.exists() or not audio_dir_path.is_dir():\n",
    "                raise FileNotFoundError(f\"Audio directory not found or not a directory: {audio_dir_path}\")\n",
    "            \n",
    "            audio_files = []\n",
    "            for ext in ['.wav', '.mp3', '.m4a', '.flac']:\n",
    "                audio_files.extend(list(audio_dir_path.rglob(f\"*{ext}\"))) # Use rglob for recursive search\n",
    "            \n",
    "            if not audio_files:\n",
    "                raise FileNotFoundError(f\"No compatible audio files (.wav, .mp3, .m4a, .flac) found in {audio_dir_path} or its subdirectories.\")\n",
    "            \n",
    "            input_audio_file = audio_files[0]\n",
    "            print(f\"Processing audio file: {input_audio_file}\")\n",
    "            \n",
    "            # Build command list (shell=False, no manual quotes needed for paths)\n",
    "            cmd_list = [\n",
    "                \"python\", \"Voice_Extractor/run_extractor.py\",\n",
    "                \"--input-audio\", str(input_audio_file),\n",
    "                \"--reference-audio\", str(reference_file.value),\n",
    "                \"--target-name\", target_name.value,\n",
    "                \"--output-base-dir\", str(output_dir.value),\n",
    "                \"--token\", hf_token.value,\n",
    "                \"--output-sr\", str(output_sr.value),\n",
    "                \"--whisper-model\", whisper_model.value,\n",
    "                \"--min-duration\", str(min_duration.value),\n",
    "                \"--merge-gap\", str(merge_gap.value),\n",
    "                \"--verification-threshold\", str(verification_threshold.value),\n",
    "                \"--concat-silence\", str(concat_silence.value),\n",
    "                \"--diar-model\", diar_model.value,\n",
    "                \"--osd-model\", osd_model.value\n",
    "            ]\n",
    "            \n",
    "            if language.value.strip():\n",
    "                cmd_list.extend([\"--language\", language.value.strip()])\n",
    "            \n",
    "            if skip_demucs.value: cmd_list.append(\"--skip-demucs\")\n",
    "            if disable_speechbrain.value: cmd_list.append(\"--disable-speechbrain\")\n",
    "            if skip_rejected_transcripts.value: cmd_list.append(\"--skip-rejected-transcripts\")\n",
    "            if dry_run.value: cmd_list.append(\"--dry-run\")\n",
    "            if debug_log.value: cmd_list.append(\"--debug\")\n",
    "            if keep_temp_files.value: cmd_list.append(\"--keep-temp-files\")\n",
    "            \n",
    "            status_message.value = \"Status: Running Voice Extractor script...\"\n",
    "            print(f\"Executing command: {' '.join(cmd_list)}\\n--- LOG START ---\")\n",
    "            \n",
    "            # Execute command and capture output (shell=False)\n",
    "            process = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                                     text=True, bufsize=1, universal_newlines=True, shell=False)\n",
    "            \n",
    "            full_process_output_lines = []\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "                full_process_output_lines.append(line)\n",
    "            exit_code = process.wait()\n",
    "            full_output_str = \"\".join(full_process_output_lines)\n",
    "            \n",
    "            print(\"--- LOG END ---\")\n",
    "            \n",
    "            if exit_code == 0:\n",
    "                status_message.value = \"<p style='color:green;'>Status: Voice extraction completed successfully!</p>\"\n",
    "                \n",
    "                run_output_dir_name = f\"{target_name.value.replace(' ', '_')}_{input_audio_file.stem}_SOLO_Split\"\n",
    "                actual_run_output_dir = Path(output_dir.value) / run_output_dir_name\n",
    "                \n",
    "                if not actual_run_output_dir.exists():\n",
    "                    print(f\"\\n‚ö†Ô∏è Warning: Expected output directory {actual_run_output_dir} not found. ZIP and HF push might fail.\")\n",
    "                    print(f\"Contents of base output directory ({output_dir.value}):\")\n",
    "                    try:\n",
    "                        for item in Path(output_dir.value).iterdir(): print(f\"  - {item.name}\")\n",
    "                    except Exception as list_e:\n",
    "                        print(f\"    Could not list contents: {list_e}\")\n",
    "                else:\n",
    "                    print(f\"\\nOutput generated in: {actual_run_output_dir}\")\n",
    "                \n",
    "                # Path for the zip file, relative to output_dir.value\n",
    "                base_zip_name = f\"{target_name.value.replace(' ', '_')}_{input_audio_file.stem}_dataset\"\n",
    "                zip_file_path_obj = Path(output_dir.value) / f\"{base_zip_name}.zip\"\n",
    "                \n",
    "                zip_created_successfully = False\n",
    "                if actual_run_output_dir.exists() and actual_run_output_dir.is_dir(): \n",
    "                    print(f\"\\nCreating ZIP archive of results: {zip_file_path_obj}\")\n",
    "                    try:\n",
    "                        # shutil.make_archive expects base_name without .zip extension\n",
    "                        # root_dir should be the parent of the directory to be zipped\n",
    "                        # base_dir is the directory to be zipped, relative to root_dir\n",
    "                        shutil.make_archive(str(Path(output_dir.value) / base_zip_name), \n",
    "                                          'zip', \n",
    "                                          root_dir=actual_run_output_dir.parent, \n",
    "                                          base_dir=actual_run_output_dir.name)\n",
    "                        print(f\"‚úÖ ZIP created successfully: {zip_file_path_obj}\")\n",
    "                        zip_created_successfully = True\n",
    "                    except Exception as zip_e:\n",
    "                        print(f\"‚ùå Error creating ZIP: {zip_e}\")\n",
    "                else:\n",
    "                    print(f\"\\nSkipping ZIP creation as output directory {actual_run_output_dir} was not found or is not a directory.\")\n",
    "\n",
    "                if zip_created_successfully and \"Download to Computer\" in output_method.value:\n",
    "                    print(\"\\nPreparing to download ZIP file...\")\n",
    "                    files.download(str(zip_file_path_obj))\n",
    "                    print(\"‚úÖ Download initiated. Check your browser downloads.\")\n",
    "                elif \"Download to Computer\" in output_method.value:\n",
    "                    print(\"\\nSkipping download as ZIP file was not created successfully.\")\n",
    "                \n",
    "                if push_to_hf.value and actual_run_output_dir.exists() and actual_run_output_dir.is_dir():\n",
    "                    print(f\"\\nPreparing to push dataset to Hugging Face: {hf_dataset_repo.value}\")\n",
    "                    from datasets import load_dataset, Audio as HFAudio # Keep import local\n",
    "                    \n",
    "                    verified_csv_files = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                    if not verified_csv_files:\n",
    "                        print(f\"‚ùå Error: No verified transcript CSV found in {actual_run_output_dir / 'transcripts_solo_verified'}. Cannot push to Hugging Face.\")\n",
    "                    else:\n",
    "                        verified_csv_path = verified_csv_files[0]\n",
    "                        print(f\"Loading dataset from {verified_csv_path}\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Load dataset. Assumes 'filename' column contains paths relative to the CSV's location OR an absolute path.\n",
    "                            # The `datasets` library often resolves relative paths against the CSV's directory.\n",
    "                            # If `run_extractor.py` creates filenames that are relative to `actual_run_output_dir`\n",
    "                            # (e.g., 'audio_clips/segment1.wav') and the CSV is in `transcripts_solo_verified`,\n",
    "                            # then paths like '../audio_clips/segment1.wav' in the CSV would work.\n",
    "                            # Or, if `data_dir` is used in `load_dataset` pointing to `actual_run_output_dir`,\n",
    "                            # then paths in CSV can be relative to that.\n",
    "                            \n",
    "                            # Simplest assumption: CSV paths are relative to actual_run_output_dir or absolute.\n",
    "                            # For casting, paths in 'filename' must be valid and accessible.\n",
    "                            # Let's assume `run_extractor.py` prepares CSVs such that `load_dataset` with `data_files` works naturally.\n",
    "                            # The `data_dir` argument in `load_dataset` can specify the root for relative paths in data_files.\n",
    "                            ds = load_dataset('csv', data_files={'train': str(verified_csv_path)}, data_dir=str(actual_run_output_dir))\n",
    "\n",
    "                            if 'filename' not in ds['train'].column_names:\n",
    "                                raise ValueError(\"CSV file must contain a 'filename' column with paths to audio files.\")\n",
    "\n",
    "                            # The 'filename' column paths should be resolvable by HFAudio. \n",
    "                            # If they are relative, they are usually relative to the `data_dir` or the location of the CSV.\n",
    "                            # `embed_external_files=True` will bundle local files, so paths must be correct.\n",
    "                            ds = ds.cast_column('filename', HFAudio(sampling_rate=int(output_sr.value)))\n",
    "                            \n",
    "                            print(f\"Pushing dataset to Hugging Face Hub: {hf_dataset_repo.value}\")\n",
    "                            ds.push_to_hub(\n",
    "                                hf_dataset_repo.value,\n",
    "                                private=hf_dataset_private.value,\n",
    "                                token=hf_token.value,\n",
    "                                embed_external_files=True\n",
    "                            )\n",
    "                            print(f\"‚úÖ Dataset pushed successfully to https://huggingface.co/datasets/{hf_dataset_repo.value}\")\n",
    "                        except Exception as hf_e:\n",
    "                            print(f\"‚ùå Error during Hugging Face dataset processing or push: {hf_e}\")\n",
    "                            print(\"Info: This might be due to incorrect paths in the CSV, issues with audio files, or Hugging Face API problems.\")\n",
    "                            import traceback\n",
    "                            traceback.print_exc() # Print full traceback for HF errors\n",
    "                elif push_to_hf.value:\n",
    "                    print(\"\\nSkipping Hugging Face push as output directory was not found or is not a directory.\")\n",
    "                \n",
    "                if actual_run_output_dir.exists() and actual_run_output_dir.is_dir():\n",
    "                    with results_output:\n",
    "                        display(HTML(\"<h2>Extraction Results Summary</h2>\"))\n",
    "                        try:\n",
    "                            concat_files = list(actual_run_output_dir.glob(\"concatenated_audio_solo/*.wav\"))\n",
    "                            if concat_files:\n",
    "                                concat_file = concat_files[0]\n",
    "                                display(HTML(f\"<h3>Concatenated audio: {concat_file.name}</h3>\"))\n",
    "                                display(Audio(str(concat_file)))\n",
    "                            else:\n",
    "                                display(HTML(\"<h3>No concatenated audio file found</h3>\"))\n",
    "                        except Exception as e:\n",
    "                            display(HTML(f\"<h3>Error displaying audio: {str(e)}</h3>\"))\n",
    "                        \n",
    "                        try:\n",
    "                            transcript_csv_files = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                            if transcript_csv_files:\n",
    "                                transcript_csv = transcript_csv_files[0]\n",
    "                                df = pd.read_csv(transcript_csv)\n",
    "                                display(HTML(f\"<h3>Transcript sample (from {transcript_csv.name}):</h3>\"))\n",
    "                                display(df.head())\n",
    "                                display(HTML(f\"<p>Total segments: {len(df)}</p>\"))\n",
    "                            else:\n",
    "                                display(HTML(\"<h3>No transcript CSV found</h3>\"))\n",
    "                        except Exception as e:\n",
    "                            display(HTML(f\"<h3>Error displaying transcript: {str(e)}</h3>\"))\n",
    "            else:\n",
    "                # Check captured output for the Demucs error message\n",
    "                if \"Demucs failed! (RC: -9)\" in full_output_str:\n",
    "                    error_html = \"<p style='color:red;'><b>Error: Demucs ran out of memory (RC: -9).</b> This is common in Colab with large files.</p>\"\n",
    "                    error_html += \"<p style='color:orange;'><b>SOLUTION:</b> Ensure 'Skip Demucs Vocal Separation' option is checked and try again. If audio is not pre-separated, this step is vital but memory-intensive.</p>\"\n",
    "                    status_message.value = error_html\n",
    "                    print(\"\\n‚ùå ERROR: Demucs ran out of memory (RC: -9).\")\n",
    "                    print(\"SOLUTION: Check the 'Skip Demucs Vocal Separation' option and try again.\")\n",
    "                else:\n",
    "                    status_message.value = f\"<p style='color:red;'>Error: Voice extraction failed with exit code {exit_code}. Check logs for details.</p>\"\n",
    "                    print(f\"\\n‚ùå Process failed with exit code: {exit_code}\")\n",
    "                \n",
    "        except FileNotFoundError as e:\n",
    "            status_message.value = f\"<p style='color:red;'>File Not Found Error: {str(e)}</p>\"\n",
    "            print(f\"‚ùå File Not Found Error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            status_message.value = f\"<p style='color:red;'>An unexpected error occurred: {str(e)}</p>\"\n",
    "            print(f\"‚ùå An unexpected error occurred: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Re-enable UI\n",
    "    start_btn.disabled = False\n",
    "    start_btn.description = \"üöÄ Start Extraction\"\n",
    "    start_btn.icon = \"play\"\n",
    "    validate_inputs() # Re-validate to ensure button state is correct\n",
    "\n",
    "# Attach event to button\n",
    "start_btn.on_click(run_extraction)\n",
    "\n",
    "# Group related settings\n",
    "segment_params = widgets.VBox([min_duration, merge_gap, verification_threshold, concat_silence, \n",
    "                             disable_speechbrain, skip_rejected_transcripts])\n",
    "model_params = widgets.VBox([diar_model, osd_model])\n",
    "debug_params = widgets.VBox([dry_run, debug_log, keep_temp_files])\n",
    "\n",
    "# Create accordion for advanced settings\n",
    "advanced_accordion = widgets.Accordion(\n",
    "    children=[segment_params, model_params, debug_params]\n",
    ")\n",
    "advanced_accordion.set_title(0, 'Segment Parameters')\n",
    "advanced_accordion.set_title(1, 'Model Options')\n",
    "advanced_accordion.set_title(2, 'Debug & Temp Files')\n",
    "\n",
    "# Create final layout\n",
    "main_layout = widgets.VBox([\n",
    "    widgets.HTML(\"<h1>Voice Extractor - Google Colab Interface</h1>\"),\n",
    "    widgets.HTML(\"<p>Extract solo voice segments of a target speaker from multi-speaker recordings. Ensure you have accepted Hugging Face model terms (see instructions below).</p>\"),\n",
    "    \n",
    "    auth_section,\n",
    "    hf_token,\n",
    "    \n",
    "    input_section,\n",
    "    audio_dir,\n",
    "    reference_file,\n",
    "    target_name,\n",
    "    output_dir,\n",
    "    \n",
    "    processing_section,\n",
    "    output_sr,\n",
    "    whisper_model,\n",
    "    language,\n",
    "    \n",
    "    performance_section,\n",
    "    memory_warning,\n",
    "    widgets.HBox([skip_demucs, skip_demucs_description]),\n",
    "    \n",
    "    advanced_section,\n",
    "    advanced_accordion,\n",
    "    \n",
    "    output_section,\n",
    "    output_method,\n",
    "    push_to_hf,\n",
    "    hf_dataset_repo,\n",
    "    hf_dataset_private,\n",
    "    \n",
    "    widgets.HBox([start_btn, validation_message], layout=widgets.Layout(align_items='center')),\n",
    "    status_message,\n",
    "    create_section(\"Processing Log\"),\n",
    "    log_output,\n",
    "    create_section(\"Results\"),\n",
    "    results_output\n",
    "])\n",
    "\n",
    "# Initialize validation\n",
    "validate_inputs()\n",
    "\n",
    "# Display the UI\n",
    "display(main_layout)\n",
    "print(\"Voice Extractor UI ready! Please fill the form and start extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8137fb8",
   "metadata": {},
   "source": [
    "# Voice Extractor - Usage Instructions\n",
    "\n",
    "This notebook provides a graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, which identifies, isolates, and transcribes clean solo segments of a target speaker from multi-speaker audio recordings.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Authentication**: Enter your HuggingFace User Access Token (with `read` access, `write` if pushing datasets). This is required to download PyAnnote models.\n",
    "2. **Input Files**:\n",
    "   - **Audio Directory**: Specify the GDrive folder containing your audio files (e.g., `/content/drive/MyDrive/my_podcast_episodes`). The tool will search this folder and its subfolders for the first compatible audio file (`.wav`, `.mp3`, `.m4a`, `.flac`).\n",
    "   - **Reference Audio**: Provide a path to a clean audio file (5-30 seconds, `.wav` recommended) containing *only* your target speaker's voice. This is crucial for speaker identification.\n",
    "   - **Target Name**: A descriptive name for your target speaker (e.g., `JohnDoe`, `Host_Alice`). This will be used in output filenames.\n",
    "   - **Output Directory**: A GDrive folder where all results (extracted audio, transcripts, ZIP file) will be saved (e.g., `/content/drive/MyDrive/VoiceExtractor_Results`).\n",
    "3. **Processing Options**: \n",
    "   - **Output Sample Rate**: Sample rate for the extracted audio files. `24000` Hz is a good balance for voice.\n",
    "   - **Whisper Model**: Choose the ASR model for transcription. Larger models are more accurate but slower. `large-v3` is recommended for high accuracy.\n",
    "   - **Language Code**: ISO code for the language spoken in the audio (e.g., `en` for English, `es` for Spanish). Leave blank for auto-detection by Whisper (can be less reliable).\n",
    "4. **Performance & Memory Options**:\n",
    "   - **Skip Demucs Vocal Separation**: **Highly recommended to keep checked in Colab**, especially for longer files, to avoid out-of-memory errors. Only uncheck if your input audio is *not* already vocally isolated (e.g., raw music with vocals) AND you are processing very short files or have ample RAM. If your audio is already clean speech (like a podcast recording or dialogue), Demucs is often unnecessary.\n",
    "5. **Advanced Settings (Accordion)**:\n",
    "   - **Segment Parameters**: Fine-tune how audio segments are defined and verified.\n",
    "   - **Model Options**: Select specific PyAnnote models if needed (defaults are usually fine).\n",
    "   - **Debug & Temp Files**: Useful for troubleshooting. `Dry Run` is great for testing your setup quickly.\n",
    "6. **Output Handling & Export**:\n",
    "   - **Output Methods**: Choose whether to save a ZIP of the results to GDrive, download it to your computer, or both.\n",
    "   - **Push to Hugging Face Hub**: Optionally, upload the processed dataset (audio clips and transcripts) to a Hugging Face Dataset repository. (Note: Author mentioned this might be \"broken atm\" - functionality may vary. Ensure your CSV paths are correct and accessible for the `datasets` library if using this).\n",
    "7. **Start Processing**: Once all *required fields (marked with `*`) are filled, the \"üöÄ Start Extraction\" button will become active. Click it to begin.\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- **Google Drive**: This notebook requires Google Drive to be mounted for accessing input audio and saving results.\n",
    "- **Hugging Face Account & Token**: You *must* have a Hugging Face account and a User Access Token. Create one at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n",
    "- **Accept Model Terms**: Before first use, you need to visit and accept the terms of use for the following PyAnnote models on Hugging Face (while logged in):\n",
    "  - [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "  - [pyannote/overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
    "  - (Implicitly through diarization) [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0) or similar.\n",
    "  Failure to do so will result in authentication errors when the script tries to download these models.\n",
    "- **Reference Audio Quality**: The quality and specificity of your reference audio significantly impact the accuracy of target speaker extraction.\n",
    "   - The script will use the first compatible audio file found in the specified `Audio Directory` (and its subdirectories).\n",
    "- **Colab Runtime**: For best performance, use a GPU runtime (Runtime ‚Üí Change runtime type ‚Üí T4 GPU). Processing can be very slow on CPU.\n",
    "- **Long Audio Files**: Processing very long audio files can be time-consuming and memory-intensive. Consider splitting them into smaller chunks if you encounter issues.\n",
    "- **First Run**: The first time you run the script, it will download models, which may take some time.\n",
    "\n",
    "For more detailed documentation on the underlying tool, visit the [Voice Extractor GitHub repository](https://github.com/ReisCook/Voice_Extractor).\n",
    "If you encounter issues specific to this Colab interface, check the Processing Log for error messages.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
